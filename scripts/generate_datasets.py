#!/usr/bin/env python3
"""
Script to generate training datasets for Japanese GEC multi-task learning.
"""

import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from utils.dataset_generator import DatasetGenerator


def main():
    """Generate all training datasets."""
    print("=== Japanese GEC Multi-Task Dataset Generator ===\n")
    
    # Check if required files exist
    gec_corpus_path = "exclude/japanese_gec_corpus/corpus_v0.txt"
    autojqe_datasets_dir = "exclude/autoJQE/datasets"
    
    missing_files = []
    if not os.path.exists(gec_corpus_path):
        missing_files.append(gec_corpus_path)
    if not os.path.exists(autojqe_datasets_dir):
        missing_files.append(autojqe_datasets_dir)
    
    if missing_files:
        print("âŒ Missing required files:")
        for file in missing_files:
            print(f"   - {file}")
        return
    
    # Initialize generator (now uses unified prompts API)
    generator = DatasetGenerator()
    
    # Generate all datasets
    print("ğŸš€ Starting dataset generation...\n")
    datasets = generator.generate_all_datasets(gec_corpus_path, autojqe_datasets_dir)
    
    # Export datasets
    print("\nğŸ“ Exporting individual task datasets...")
    generator.export_to_jsonl(datasets, output_dir="datasets")
    
    print("\nğŸ“¦ Creating combined dataset for multi-task training...")
    generator.export_combined_dataset(datasets, "datasets/combined")
    
    print("\nğŸ“š Creating curriculum learning datasets...")
    generator.export_curriculum_datasets(datasets, "datasets/curriculum")
    
    print("\nâœ… Dataset generation completed!")
    print("\nGenerated directories (MLX LoRA format):")
    print("  ğŸ“‚ datasets/")
    for task_name in datasets.keys():
        if datasets[task_name]:  # Only show non-empty datasets
            print(f"     ğŸ“‚ {task_name}/ (train.jsonl, valid.jsonl, test.jsonl)")
    print("     ğŸ“‚ combined/ (train.jsonl, valid.jsonl, test.jsonl)")
    print("  ğŸ“‚ datasets/curriculum/")
    print("     ğŸ“‚ stage1_basic_correction/ (train.jsonl, valid.jsonl, test.jsonl)")
    print("     ğŸ“‚ stage2_error_detection/ (train.jsonl, valid.jsonl, test.jsonl)") 
    print("     ğŸ“‚ stage3_precise_correction/ (train.jsonl, valid.jsonl, test.jsonl)")
    print("     ğŸ“‚ stage4_quality_assessment/ (train.jsonl, valid.jsonl, test.jsonl)")
    print("     ğŸ“– curriculum_guide.md")
    
    print("\nğŸ’¡ Training Commands:")
    print("  ğŸ¯ Single-task: mlx_lm.lora --data datasets/gec_end_to_end")
    print("  ğŸ”„ Multi-task: mlx_lm.lora --data datasets/combined")
    print("  ğŸ“š Curriculum: mlx_lm.lora --data datasets/curriculum/stage1_basic_correction")
    print("  ğŸ“– See curriculum_guide.md for detailed curriculum training steps")


if __name__ == "__main__":
    main()